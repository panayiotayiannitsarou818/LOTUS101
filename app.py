# -*- coding: utf-8 -*-
# Version: 2025-09-06 Clean stable build â€” brand: Î¨Î·Ï†Î¹Î±ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï
import re, os, json, importlib.util, datetime as dt, math, base64, unicodedata
from pathlib import Path
from io import BytesIO

import streamlit as st
import pandas as pd

# ---------------------------
# Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚ ÏƒÎµÎ»Î¯Î´Î±Ï‚ / Branding
# ---------------------------
st.set_page_config(page_title="Î¨Î·Ï†Î¹Î±ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï", page_icon="ğŸ§©", layout="wide")
st.title("Î¨Î·Ï†Î¹Î±ÎºÎ® ÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎœÎ±Î¸Î·Ï„ÏÎ½ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï")

st.markdown("""
<div style="display:flex; align-items:center; gap:10px; margin-top:-8px; margin-bottom:8px;">
  <span style="font-size:0.95rem;">ÎœÎ¹Î± Ï€Î±Î¹Î´ÎµÎ¯Î± Ï€Î¿Ï… Î²Î»Î­Ï€ÎµÎ¹ Ï„Î¿ Ï†Ï‰Ï‚ ÏƒÎµ ÏŒÎ»Î± Ï„Î± Ï€Î±Î¹Î´Î¹Î¬</span>
  <svg width="26" height="26" viewBox="0 0 64 64" aria-label="lotus" role="img">
    <g fill="#B57EDC">
      <path d="M32 8c-4 8-4 16 0 24 4-8 4-16 0-24z"/>
      <path d="M18 14c-1 7 1 14 6 20 1-8-1-16-6-20z"/>
      <path d="M46 14c-5 4-7 12-6 20 5-6 7-13 6-20z"/>
      <path d="M10 28c3 6 9 10 16 12-3-6-8-11-16-12z"/>
      <path d="M54 28c-8 1-13 6-16 12 7-2 13-6 16-12z"/>
      <path d="M20 38c3 6 8 10 12 10s9-4 12-10c-7 2-17 2-24 0z"/>
    </g>
  </svg>
</div>
""", unsafe_allow_html=True)
ROOT = Path(__file__).parent
ASSETS = ROOT / "assets"
ASSETS.mkdir(exist_ok=True)
PERSIST_LOGO_PATH = ASSETS / "persisted_logo.bin"
PERSIST_LOGO_META = ASSETS / "persisted_logo.meta.json"

# ---------------------------
# Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ¬
# ---------------------------
def _load_module(name: str, file_path: Path):
    spec = importlib.util.spec_from_file_location(name, str(file_path))
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)  # type: ignore
    return mod

def _read_file_bytes(path: Path) -> bytes:
    with open(path, "rb") as f:
        return f.read()

def _timestamped(base: str, ext: str) -> str:
    ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    import re as _re
    safe = _re.sub(r"[^A-Za-z0-9_\-\.]+", "_", base)
    return f"{safe}_{ts}{ext}"

def _check_required_files(paths):
    missing = [str(p) for p in paths if not p.exists()]
    return missing

def _inject_logo(logo_bytes: bytes, width_px: int = 140, mime: str = "image/png"):
    b64 = base64.b64encode(logo_bytes).decode("ascii")
    html = f"""
    <div style="position: fixed; bottom: 38px; right: 38px; z-index: 1000;">
        <img src="data:{mime};base64,{b64}" style="width:{width_px}px; height:auto; opacity:0.95; border-radius:12px;" />
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

def _restart_app():
    # ÎšÎ±Î¸Î¬ÏÎ¹ÏƒÎµ session_state ÎºÎ»ÎµÎ¹Î´Î¹Î¬
    for k in list(st.session_state.keys()):
        if k.startswith("uploader_") or k in ("auth_ok","accepted_terms","app_enabled","last_final_path"):
            try:
                del st.session_state[k]
            except Exception:
                pass
    # ÎšÎ±Î¸Î¬ÏÎ¹ÏƒÎµ caches
    try:
        st.cache_data.clear()
    except Exception:
        pass
    try:
        st.cache_resource.clear()
    except Exception:
        pass
    # Î”Î™Î‘Î“Î¡Î‘Î¦Î— Ï€Î±ÏÎ±Î³ÏŒÎ¼ÎµÎ½Ï‰Î½ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ Î³Î¹Î± Ï€Î»Î®ÏÎ· ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒ
    try:
        for pat in ("STEP7_FINAL_SCENARIO*.xlsx", "STEP1_6_PER_SCENARIO*.xlsx", "INPUT_STEP1*.xlsx"):
            for f in ROOT.glob(pat):
                try:
                    f.unlink()
                except Exception:
                    pass
    except Exception:
        pass
    st.rerun()

def _terms_md():
    return """
**Î¥Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ® Î‘Ï€Î¿Î´Î¿Ï‡Î® ÎŒÏÏ‰Î½ Î§ÏÎ®ÏƒÎ·Ï‚**  
Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î´Î·Î»ÏÎ½ÎµÏ„Îµ ÏŒÏ„Î¹:  
- Î”ÎµÎ½ Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Îµ Ï„Î· Î»Î¿Î³Î¹ÎºÎ® Ï„Ï‰Î½ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ ÎºÎ±Î¹ Î´ÎµÎ½ Î±Î½Î±Î´Î¹Î±Î½Î­Î¼ÎµÏ„Îµ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï‡Ï‰ÏÎ¯Ï‚ Î¬Î´ÎµÎ¹Î±.  
- Î‘Î½Î±Î»Î±Î¼Î²Î¬Î½ÎµÏ„Îµ Ï„Î·Î½ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Ï„Î·Î½ Î¿ÏÎ¸ÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ ÎµÎ¹ÏƒÎ±Î³ÏŒÎ¼ÎµÎ½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.  
- Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Ï€Î±ÏÎ­Ï‡ÎµÏ„Î±Î¹ Â«Ï‰Ï‚ Î­Ï‡ÎµÎ¹Â», Ï‡Ï‰ÏÎ¯Ï‚ ÎµÎ³Î³ÏÎ·ÏƒÎ· Î³Î¹Î± Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ Ï‡ÏÎ®ÏƒÎ·.  

**Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î”Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± & ÎÎ¿Î¼Î¹ÎºÎ® Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î±**  
Â© 2025 Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï… Î Î±Î½Î±Î³Î¹ÏÏ„Î± â€” ÎŒÎ»Î± Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½Ï„Î±Î¹.  
Î“Î¹Î± Î¬Î´ÎµÎ¹Î± Ï‡ÏÎ®ÏƒÎ·Ï‚/ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚: *panayiotayiannitsarou@gmail.com*.
"""

# ---------------------------
# Î‘ÏÏ‡ÎµÎ¯Î± Ï€Î¿Ï… Î´ÎµÎ½ Î±Î»Î»Î¬Î¶Î¿Ï…Î¼Îµ (modules 1â†’7)
# ---------------------------
REQUIRED = [
    ROOT / "export_step1_6_per_scenario.py",
    ROOT / "step1_immutable_ALLINONE.py",
    ROOT / "step_2_helpers_FIXED.py",
    ROOT / "step_2_zoiroi_idiaterotites_FIXED_v3_PATCHED.py",
    ROOT / "step3_amivaia_filia_FIXED.py",
    ROOT / "step4_corrected.py",
    ROOT / "step5_enhanced.py",
    ROOT / "step6_compliant.py",
    ROOT / "step7_fixed_final.py",
]

# ---------------------------
# Sidebar: Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·, ÏŒÏÎ¿Î¹, Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿
# ---------------------------
with st.sidebar:
    st.header("ğŸ” Î ÏÏŒÏƒÎ²Î±ÏƒÎ· & Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")

    pwd = st.text_input("ÎšÏ‰Î´Î¹ÎºÏŒÏ‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚", type="password", help="ÎšÏ‰Î´Î¹ÎºÏŒÏ‚: katanomi2025")
    if "auth_ok" not in st.session_state:
        st.session_state.auth_ok = False
    if pwd:
        st.session_state.auth_ok = (pwd.strip() == "katanomi2025")
        if not st.session_state.auth_ok:
            st.error("Î›Î±Î½Î¸Î±ÏƒÎ¼Î­Î½Î¿Ï‚ ÎºÏ‰Î´Î¹ÎºÏŒÏ‚.")

    with st.expander("ğŸ“„ ÎŒÏÎ¿Î¹ Î§ÏÎ®ÏƒÎ·Ï‚ & Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î”Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±", expanded=True):
        st.markdown(_terms_md())
    st.session_state.accepted_terms = st.checkbox("âœ… Î‘Ï€Î¿Î´Î­Ï‡Î¿Î¼Î±Î¹ Ï„Î¿Ï…Ï‚ ÎŒÏÎ¿Ï…Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚", value=st.session_state.get("accepted_terms", False))

    st.session_state.app_enabled = st.toggle("â¯ï¸ Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÏÏÎ¹Î±Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚", value=st.session_state.get("app_enabled", True))

    st.divider()
    st.subheader("ğŸ–¼ï¸ Î›Î¿Î³ÏŒÏ„Ï…Ï€Î¿")
    # Auto-load persisted
    if PERSIST_LOGO_PATH.exists() and PERSIST_LOGO_META.exists():
        try:
            meta = json.loads(PERSIST_LOGO_META.read_text(encoding="utf-8"))
            mime = meta.get("mime", "image/png")
            _inject_logo(_read_file_bytes(PERSIST_LOGO_PATH), width_px=140, mime=mime)
            st.caption("Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±** Ï„Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ (ÎºÎ¬Ï„Ï‰ Î´ÎµÎ¾Î¹Î¬).")
        except Exception:
            st.warning("Î¤Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ Î´ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Ï†Î¿ÏÏ„Ï‰Î¸ÎµÎ¯.")
    # Upload & persist
    logo_file = st.file_uploader("PNG/JPG/SVG Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ)", type=["png","jpg","jpeg","svg"], key="logo_upl")
    if logo_file is not None:
        try:
            mime = getattr(logo_file, "type", "image/png") or "image/png"
            data = logo_file.read()
            _inject_logo(data, width_px=140, mime=mime)
            PERSIST_LOGO_PATH.write_bytes(data)
            PERSIST_LOGO_META.write_text(json.dumps({"mime": mime, "saved_at": dt.datetime.now().isoformat()}), encoding="utf-8")
            st.success("Î¤Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ **Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î¼ÏŒÎ½Î¹Î¼Î±** ÎºÎ±Î¹ Î¸Î± Ï†Î¿ÏÏ„ÏÎ½ÎµÏ„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±.")
        except Exception as e:
            st.warning(f"Î‘Î½ÎµÎ²Î¬ÏƒÏ„Î·ÎºÎµ, Î±Î»Î»Î¬ Î´ÎµÎ½ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î¼ÏŒÎ½Î¹Î¼Î±: {e}")
    colL, colR = st.columns([1,1])
    with colL:
        if st.button("ğŸ§¹ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿Ï… Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿Ï…", use_container_width=True):
            try:
                if PERSIST_LOGO_PATH.exists(): PERSIST_LOGO_PATH.unlink()
                if PERSIST_LOGO_META.exists(): PERSIST_LOGO_META.unlink()
                st.success("Î”Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ Ï„Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿.")
                st.experimental_rerun()
            except Exception as e:
                st.error(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î¿Ï: {e}")
    with colR:
        st.caption("Î¤Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ Ï†Î¿ÏÏ„ÏÎ½ÎµÏ„Î±Î¹ Ï€Î¬Î½Ï„Î± Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±.")

# ---------------------------
# Î ÏÎ»ÎµÏ‚ Ï€ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î±Ï‚
# ---------------------------
if not st.session_state.auth_ok:
    st.warning("ğŸ” Î•Î¹ÏƒÎ¬Î³ÎµÏ„Îµ Ï„Î¿Î½ ÏƒÏ‰ÏƒÏ„ÏŒ ÎºÏ‰Î´Î¹ÎºÏŒ Î³Î¹Î± Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· (katanomi2025).")
    st.stop()

if not st.session_state.accepted_terms:
    st.warning("âœ… Î“Î¹Î± Î½Î± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÎµÏ„Îµ, Î±Ï€Î¿Î´ÎµÏ‡Î¸ÎµÎ¯Ï„Îµ Ï„Î¿Ï…Ï‚ ÎŒÏÎ¿Ï…Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚ (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬).")
    st.stop()

if not st.session_state.app_enabled:
    st.info("â¸ï¸ Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÎµÎ¯Î½Î±Î¹ Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î·. Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î·Î½ Î±Ï€ÏŒ Ï„Î± Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬.")
    st.stop()

# ---------------------------
# ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ modules
# ---------------------------
st.subheader("ğŸ“¦ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½")
missing = _check_required_files(REQUIRED)
if missing:
    st.error("âŒ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Î±ÏÏ‡ÎµÎ¯Î±:\n" + "\n".join(f"- {m}" for m in missing))
else:
    st.success("âœ… ÎŒÎ»Î± Ï„Î± Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î²ÏÎ­Î¸Î·ÎºÎ±Î½.")

st.divider()

# ---------------------------
# ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎŸÎ›Î‘ (Î’Î®Î¼Î±Ï„Î± 1â†’7)
# ---------------------------
st.header("ğŸš€ Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£")
up_all = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ Î±ÏÏ‡Î¹ÎºÏŒ Excel (Î³Î¹Î± 1â†’7)", type=["xlsx"], key="uploader_all")
colA, colB, colC = st.columns([1,1,1])
with colA:
    pick_step4_all = st.selectbox("ÎšÎ±Î½ÏŒÎ½Î±Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÏ„Î¿ Î’Î®Î¼Î± 4", ["best", "first", "strict"], index=0, key="pick_all")
with colB:
    final_name_all = st.text_input("ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î¤ÎµÎ»Î¹ÎºÎ¿Ï Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î¿Ï‚", value=_timestamped("STEP7_FINAL_SCENARIO", ".xlsx"))
with colC:
    if up_all is not None:
        try:
            df_preview = pd.read_excel(up_all, sheet_name=0)
            N = df_preview.shape[0]
            min_classes = max(2, math.ceil(N/25)) if N else 0
            st.metric("ÎœÎ±Î¸Î·Ï„Î­Ï‚ / Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î± Ï„Î¼Î®Î¼Î±Ï„Î±", f"{N} / {min_classes}")
        except Exception:
            st.caption("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·.")

if st.button("ğŸš€ Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£", type="primary", use_container_width=True):
    if missing:
        st.error("Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„Î® Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: Î»ÎµÎ¯Ï€Î¿Ï…Î½ modules.")
    elif up_all is None:
        st.warning("Î ÏÏÏ„Î± Î±Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Excel.")
    else:
        try:
            input_path = ROOT / _timestamped("INPUT_STEP1", ".xlsx")
            with open(input_path, "wb") as f:
                f.write(up_all.getbuffer())

            m = _load_module("export_step1_6_per_scenario", ROOT / "export_step1_6_per_scenario.py")
            s7 = _load_module("step7_fixed_final", ROOT / "step7_fixed_final.py")

            step6_path = ROOT / _timestamped("STEP1_6_PER_SCENARIO", ".xlsx")
            st.session_state["last_step6_path_pending"] = str(step6_path)
            with st.spinner("Î¤ÏÎ­Ï‡Î¿Ï…Î½ Ï„Î± Î’Î®Î¼Î±Ï„Î± 1â†’6..."):
                m.build_step1_6_per_scenario(str(input_path), str(step6_path), pick_step4=pick_step4_all)

            with st.spinner("Î¤ÏÎ­Ï‡ÎµÎ¹ Ï„Î¿ Î’Î®Î¼Î± 7..."):
                xls = pd.ExcelFile(step6_path)
                sheet_names = [s for s in xls.sheet_names if s != "Î£ÏÎ½Î¿ÏˆÎ·"]
                if not sheet_names:
                    st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ sheets ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ (ÎµÎºÏ„ÏŒÏ‚ Î±Ï€ÏŒ 'Î£ÏÎ½Î¿ÏˆÎ·').")
                else:
                    df0 = pd.read_excel(step6_path, sheet_name=sheet_names[0])
                    scen_cols = [c for c in df0.columns if re.match(r"^Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_\d+$", str(c))]
                    if not scen_cols:
                        st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ„Î®Î»ÎµÏ‚ Ï„ÏÏ€Î¿Ï… 'Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_N'.")
                    else:
                        pick = s7.pick_best_scenario(df0.copy(), scen_cols, random_seed=42)
                        best = pick.get("best")
                        if not best or "scenario_col" not in best:
                            st.error("Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÎµÎ½Î±ÏÎ¯Î¿Ï….")
                        else:
                            winning_col = best["scenario_col"]
                            final_out = ROOT / final_name_all
                            full_df = pd.read_excel(step6_path, sheet_name=sheet_names[0]).copy()
                            with pd.ExcelWriter(final_out, engine="xlsxwriter") as w:
                                full_df.to_excel(w, index=False, sheet_name="FINAL_SCENARIO")
                                labels = sorted(
                                    [str(v) for v in full_df[winning_col].dropna().unique() if re.match(r"^Î‘\d+$", str(v))],
                                    key=lambda x: int(re.search(r"\d+", x).group(0))
                                )
                                for lab in labels:
                                    sub = full_df.loc[full_df[winning_col] == lab, ["ÎŸÎÎŸÎœÎ‘", winning_col]].copy()
                                    sub = sub.rename(columns={winning_col: "Î¤ÎœÎ—ÎœÎ‘"})
                                    sub.to_excel(w, index=False, sheet_name=str(lab))

                            st.session_state["last_final_path"] = str(final_out.resolve()); st.session_state["last_step6_path"] = st.session_state.get("last_step6_path_pending")

                            st.success(f"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ. ÎÎ¹ÎºÎ·Ï„Î®Ï‚: ÏƒÏ„Î®Î»Î· {winning_col}")
                            st.download_button(
                                "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Î¤ÎµÎ»Î¹ÎºÏŒ Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± (1â†’7)",
                                data=_read_file_bytes(final_out),
                                file_name=final_out.name,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                            st.caption("â„¹ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÎºÎ±Î¹ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±** Î±Ï€ÏŒ Ï„Î± Â«ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬Â».")
        except Exception as e:
            st.exception(e)

st.divider()

# ---------------------------
# ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ â€” Î‘Î¥Î£Î¤Î—Î¡Î‘ (AUTO Î±Ï€ÏŒ Î’Î®Î¼Î± 7)
# ---------------------------
# Î‘Î¥Î£Î¤Î—Î¡ÎŸ: ÎœÎŸÎÎŸ Î±Ï€ÏŒ session_state (ÎºÎ±Î¼Î¯Î± ÏƒÎ¬ÏÏ‰ÏƒÎ· Î´Î¯ÏƒÎºÎ¿Ï…)
def _find_latest_final_path() -> Path | None:
    p = st.session_state.get("last_final_path")
    if p and Path(p).exists():
        return Path(p)
    return None

st.header("ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½")
st.markdown("\n".join([
    "ğŸ“Š **Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ (AUTO):** Î´Î¹Î±Î²Î¬Î¶ÎµÎ¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Ï„Î¿ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î¿ `STEP7_FINAL_SCENARIO_*.xlsx` (Î´ÎµÎ½ Î¶Î·Ï„Î¬ upload).",
    "**Î‘Ï€Î±Î¹Ï„ÎµÎ¯:** `FINAL_SCENARIO` Î¼Îµ **Î±ÎºÏÎ¹Î²ÏÏ‚ Î¼Î¯Î±** ÏƒÏ„Î®Î»Î· `Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_N` â†’ Î±Ï…Ï„Î® Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Ï‰Ï‚ `Î¤ÎœÎ—ÎœÎ‘`.",
]))

final_path = _find_latest_final_path()
if not final_path:
    st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Î’Î®Î¼Î±Ï„Î¿Ï‚ 7. Î ÏÏÏ„Î± Ï„ÏÎ­Î¾Îµ Â«Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£Â».")
else:
    try:
        xl = pd.ExcelFile(final_path)
        sheets = xl.sheet_names
        st.success(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ: **{final_path.name}** | Sheets: {', '.join(sheets)}")
    except Exception as e:
        xl = None
        st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚: {e}")

    if xl is not None and "FINAL_SCENARIO" in sheets:
        used_df = xl.parse("FINAL_SCENARIO")
        scen_cols = [c for c in used_df.columns if re.match(r"^Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_\d+$", str(c))]
        if len(scen_cols) != 1:
            st.error("âŒ Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ **Î±ÎºÏÎ¹Î²ÏÏ‚ Î¼Î¯Î±** ÏƒÏ„Î®Î»Î· `Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_N` ÏƒÏ„Î¿ FINAL_SCENARIO.")
        else:
            used_df["Î¤ÎœÎ—ÎœÎ‘"] = used_df[scen_cols[0]].astype(str).str.strip()

            # --- Auto rename columns for Î¦Î™Î›ÎŸÎ™/Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î— ÏŒÏ€Î¿Ï… Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
            def auto_rename_columns(df: pd.DataFrame):
                mapping = {}
                if "Î¦Î™Î›ÎŸÎ™" not in df.columns:
                    for c in df.columns:
                        if "Î¦Î™Î›" in str(c).upper():
                            mapping[c] = "Î¦Î™Î›ÎŸÎ™"
                            break
                if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in df.columns and "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£" in df.columns:
                    mapping["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£"] = "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"
                return df.rename(columns=mapping), mapping
            used_df, rename_map = auto_rename_columns(used_df)

            # ---- Matching helpers
            def _strip_diacritics(s: str) -> str:
                nfkd = unicodedata.normalize("NFD", s)
                return "".join(ch for ch in nfkd if not unicodedata.combining(ch))
            def _canon_name(s: str) -> str:
                s = (str(s) if s is not None else "").strip()
                s = s.strip("[]'\" ")
                s = re.sub(r"\s+", " ", s)
                s = _strip_diacritics(s).upper()
                return s
            def _tokenize_name(canon: str):
                return [t for t in re.split(r"[^A-Z0-9]+", canon) if t]
            def _best_name_match(target_canon: str, candidates: list[str]) -> str | None:
                if target_canon in candidates:
                    return target_canon
                tks = set(_tokenize_name(target_canon))
                if not tks:
                    return None
                best = None; best_score = 0.0
                for c in candidates:
                    cks = set(_tokenize_name(c))
                    if not cks:
                        continue
                    inter = tks & cks
                    jacc = len(inter) / max(1, len(tks | cks))
                    prefix = any(c.startswith(tok) or target_canon.startswith(tok) for tok in inter) if inter else False
                    score = jacc + (0.2 if prefix else 0.0)
                    if score > best_score:
                        best = c; best_score = score
                if best_score >= 0.34:
                    return best
                return None

            # ---- Î£Ï…Î³ÎºÏÎ¿ÏÏƒÎµÎ¹Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚ (Î¼Î­Ï„ÏÎ·ÏƒÎ·/Î¿Î½ÏŒÎ¼Î±Ï„Î±)
            def compute_conflict_counts_and_names(df: pd.DataFrame):
                if "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
                    return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)
                if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in df.columns:
                    return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)
                df = df.copy()
                df["__C"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
                cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
                canon_names = list(df["__C"].astype(str).unique())
                index_by = {cn: i for i, cn in enumerate(df["__C"])}
                def parse_targets(cell):
                    raw = str(cell) if cell is not None else ""
                    parts = [p.strip() for p in re.split(r"[;,/|\n]", raw) if p.strip()]
                    return [_canon_name(p) for p in parts]
                counts = [0]*len(df); names = [""]*len(df)
                for i, row in df.iterrows():
                    my_class = cls.iloc[i]
                    targets = parse_targets(row.get("Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—",""))
                    same = []
                    for t in targets:
                        j = index_by.get(t)
                        if j is None:
                            match = _best_name_match(t, canon_names)
                            j = index_by.get(match) if match else None
                        if j is not None and cls.iloc[j] == my_class and df.loc[i, "__C"] != df.loc[j, "__C"]:
                            same.append(df.loc[j, "ÎŸÎÎŸÎœÎ‘"])
                    counts[i] = len(same)
                    names[i] = ", ".join(same)
                return pd.Series(counts, index=df.index), pd.Series(names, index=df.index)

            # ---- Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚
            def list_broken_mutual_pairs(df: pd.DataFrame) -> pd.DataFrame:
                fcol = next((c for c in ["Î¦Î™Î›ÎŸÎ™","Î¦Î™Î›ÎŸÎ£","Î¦Î™Î›Î™Î‘"] if c in df.columns), None)
                if fcol is None or "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
                    return pd.DataFrame(columns=["A","A_Î¤ÎœÎ—ÎœÎ‘","B","B_Î¤ÎœÎ—ÎœÎ‘"])
                df = df.copy()
                df["__C"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
                name_to_original = dict(zip(df["__C"], df["ÎŸÎÎŸÎœÎ‘"].astype(str)))
                class_by_name = dict(zip(df["__C"], df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()))
                canon_names = list(df["__C"].astype(str).unique())
                def parse_list(cell):
                    raw = str(cell) if cell is not None else ""
                    parts = [p.strip() for p in re.split(r"[;,/|\n]", raw) if p.strip()]
                    return [_canon_name(p) for p in parts]
                friends_map = {}
                for i, cn in enumerate(df["__C"]):
                    raw_targets = parse_list(df.loc[i, fcol])
                    resolved = []
                    for t in raw_targets:
                        if t in canon_names:
                            resolved.append(t)
                        else:
                            match = _best_name_match(t, canon_names)
                            if match:
                                resolved.append(match)
                    friends_map[cn] = set(resolved)
                rows = []
                for a, fa in friends_map.items():
                    for b in fa:
                        fb = friends_map.get(b, set())
                        if a in fb and class_by_name.get(a) != class_by_name.get(b):
                            rows.append({
                                "A": name_to_original.get(a, a), "A_Î¤ÎœÎ—ÎœÎ‘": class_by_name.get(a,""),
                                "B": name_to_original.get(b, b), "B_Î¤ÎœÎ—ÎœÎ‘": class_by_name.get(b,"")
                            })
                return pd.DataFrame(rows).drop_duplicates()

            # ---- Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÏƒÏ„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½
            def generate_stats(df: pd.DataFrame) -> pd.DataFrame:
                df = df.copy()
                if "Î¤ÎœÎ—ÎœÎ‘" in df:
                    df["Î¤ÎœÎ—ÎœÎ‘"] = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
                boys = df[df.get("Î¦Î¥Î›ÎŸ","").astype(str).str.upper().eq("Î‘")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
                girls = df[df.get("Î¦Î¥Î›ÎŸ","").astype(str).str.upper().eq("Îš")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
                edus = df[df.get("Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥" in df else pd.Series(dtype=int)
                z = df[df.get("Î–Î©Î—Î¡ÎŸÎ£","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î–Î©Î—Î¡ÎŸÎ£" in df else pd.Series(dtype=int)
                id_ = df[df.get("Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘" in df else pd.Series(dtype=int)
                g = df[df.get("ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î" in df else pd.Series(dtype=int)
                total = df.groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¤ÎœÎ—ÎœÎ‘" in df else pd.Series(dtype=int)

                try:
                    c_counts, _ = compute_conflict_counts_and_names(df)
                    cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
                    conf_by_class = c_counts.groupby(cls).sum().astype(int)
                except Exception:
                    conf_by_class = pd.Series(dtype=int)

                try:
                    pairs = list_broken_mutual_pairs(df)
                    if pairs.empty:
                        broken = pd.Series({tm: 0 for tm in df["Î¤ÎœÎ—ÎœÎ‘"].dropna().astype(str).str.strip().unique()})
                    else:
                        counts = {}
                        for _, row in pairs.iterrows():
                            counts[row["A_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["A_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                            counts[row["B_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["B_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                        broken = pd.Series(counts).astype(int)
                except Exception:
                    broken = pd.Series(dtype=int)

                stats = pd.DataFrame({
                    "Î‘Î“ÎŸÎ¡Î™Î‘": boys,
                    "ÎšÎŸÎ¡Î™Î¤Î£Î™Î‘": girls,
                    "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": edus,
                    "Î–Î©Î—Î¡ÎŸÎ™": z,
                    "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": id_,
                    "Î“ÎÎ©Î£Î— Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": g,
                    "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": conf_by_class,
                    "Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘": broken,
                    "Î£Î¥ÎÎŸÎ›ÎŸ ÎœÎ‘Î˜Î—Î¤Î©Î": total,
                }).fillna(0).astype(int)

                try:
                    stats = stats.sort_index(key=lambda x: x.str.extract(r"(\d+)")[0].astype(float))
                except Exception:
                    stats = stats.sort_index()
                return stats

            def export_stats_to_excel(stats_df: pd.DataFrame) -> BytesIO:
                output = BytesIO()
                with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
                    stats_df.to_excel(writer, index=True, sheet_name="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬", index_label="Î¤ÎœÎ—ÎœÎ‘")
                    wb = writer.book; ws = writer.sheets["Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬"]
                    header_fmt = wb.add_format({"bold": True, "valign":"vcenter", "text_wrap": True, "border":1})
                    for col_idx, value in enumerate(["Î¤ÎœÎ—ÎœÎ‘"] + list(stats_df.columns)):
                        ws.write(0, col_idx, value, header_fmt)
                    for i in range(0, len(stats_df.columns)+1):
                        ws.set_column(i, i, 18)
                output.seek(0)
                return output

            # ---- UI (tabs ÏŒÏ€Ï‰Ï‚ ÏƒÏ„Î¿ mockup)
            tab1, tab2, tab3 = st.tabs([
                "ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ (1 sheet)",
                "âŒ Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ (ÏŒÎ»Î± Ï„Î± sheets) â€” ÎˆÎ¾Î¿Î´Î¿Ï‚: Î Î»Î®ÏÎµÏ‚ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿ + Î£ÏÎ½Î¿ÏˆÎ·",
                "âš ï¸ ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î·",
            ])

            with tab1:
                st.subheader("ğŸ“ˆ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î³Î¹Î± Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ Sheet")
                st.selectbox("Î”Î¹Î¬Î»ÎµÎ¾Îµ sheet", ["FINAL_SCENARIO"], key="sheet_choice", index=0)
                with st.expander("ğŸ” Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ·/ÎœÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚", expanded=False):
                    st.write("Î‘Ï…Ï„ÏŒÎ¼Î±Ï„ÎµÏ‚ Î¼ÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚:", rename_map if rename_map else "â€”")
                    required_cols = ["ÎŸÎÎŸÎœÎ‘","Î¦Î¥Î›ÎŸ","Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","Î¦Î™Î›ÎŸÎ™","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—",]
                    missing_cols = [c for c in required_cols if c not in used_df.columns]
                    st.write("Î›ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î®Î»ÎµÏ‚:", missing_cols if missing_cols else "â€”")
    if missing_cols:
        st.info("Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ/Î´Î¹ÏŒÏÎ¸Ï‰ÏƒÎµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î»ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î¿ Excel ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†ÏŒÏÏ„Ï‰ÏƒÎ­ Ï„Î¿.")
                stats_df = generate_stats(used_df)
                st.dataframe(stats_df, use_container_width=True)
                st.download_button(
                    "ğŸ“¥ Î•Î¾Î±Î³Ï‰Î³Î® ÎœÎŸÎÎŸ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ (Excel)",
                    data=export_stats_to_excel(stats_df).getvalue(),
                    file_name=f"statistika_STEP7_FINAL_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )

            with tab2:
                st.subheader("ğŸ’” Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚")
                pairs = list_broken_mutual_pairs(used_df)
                if pairs.empty:
                    st.success("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚.")
                else:
                    st.dataframe(pairs, use_container_width=True)
                    counts = {}
                    for _, row in pairs.iterrows():
                        counts[row["A_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["A_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                        counts[row["B_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["B_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                    summary = pd.DataFrame.from_dict(counts, orient="index", columns=["Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î‘Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚"]).sort_index()
                    st.write("Î£ÏÎ½Î¿ÏˆÎ· Î±Î½Î¬ Ï„Î¼Î®Î¼Î±:")
                    st.dataframe(summary, use_container_width=True)

            with tab3:
                st.subheader("âš ï¸ ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î·")
                counts, names = compute_conflict_counts_and_names(used_df)
                conflict_students = used_df.copy()
                conflict_students["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£"] = counts.astype(int)
                conflict_students["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"] = names
                conflict_students = conflict_students.loc[conflict_students["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£"] > 0, ["ÎŸÎÎŸÎœÎ‘","Î¤ÎœÎ—ÎœÎ‘","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"]]
                if conflict_students.empty:
                    st.success("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ…Î³ÎºÏÎ¿ÏÏƒÎµÎ¹Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î·Ï‚ Î¯Î´Î¹Î±Ï‚ Ï„Î¬Î¾Î·Ï‚.")
                else:
                    st.dataframe(conflict_students.sort_values(["Î¤ÎœÎ—ÎœÎ‘","ÎŸÎÎŸÎœÎ‘"]), use_container_width=True)

st.divider()

# ---------------------------
# â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· (Î¼Î¯Î± ÎºÎ±Î¹ ÎºÎ±Î»Î®)
# ---------------------------
st.header("â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·")
st.write("ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ app.")
if st.button("â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· Ï„ÏÏÎ±", type="secondary", use_container_width=True, key="restart_btn"):
    _restart_app()

st.divider()

# ---------------------------
# ğŸ” Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î£ÎµÎ½Î¬ÏÎ¹Î± (Î’Î®Î¼Î±Ï„Î± 1â†’6) â€” Ï„ÎµÎ»ÎµÏ…Ï„Î±Î¯Î¿
# ---------------------------
st.header("ğŸ” Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î£ÎµÎ½Î¬ÏÎ¹Î± (Î’Î®Î¼Î±Ï„Î± 1â†’6)")
last_step6 = st.session_state.get("last_step6_path")
if last_step6 and Path(last_step6).exists():
    st.success("Î˜Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±** Ï„Î¿ Ï€Î¹Î¿ Ï€ÏÏŒÏƒÏ†Î±Ï„Î¿ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± Î’Î®Î¼Î±Ï„Î¿Ï‚ 6 (ÏŒÎ»Î± Ï„Î± ÏƒÎµÎ½Î¬ÏÎ¹Î±).")
    with open(last_step6, "rb") as _f:
        st.download_button("â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Excel (1â†’6)", data=_f.read(), file_name=Path(last_step6).name,
                          mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
    st.caption(f"Î Î·Î³Î®: {Path(last_step6).name}")
    st.divider()
st.write("Î•Î½ÏŒÏ„Î·Ï„Î± ÏƒÏ€Î¬Î½Î¹Î±Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚, Î¼ÏŒÎ½Î¿ Î³Î¹Î± Î­Î»ÎµÎ³Ï‡Î¿: Ï€Î±ÏÎ¬Î³ÎµÎ¹ Excel Î¼Îµ ÏŒÎ»Î± Ï„Î± ÏƒÎµÎ½Î¬ÏÎ¹Î± (Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_1, â€¦) ÎºÎ±Î¹ ÏƒÏÎ½Î¿ÏˆÎ·.")

up_16 = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ Î±ÏÏ‡Î¹ÎºÏŒ Excel (Î³Î¹Î± 1â†’6)", type=["xlsx"], key="uploader_16")
col1, col2, col3 = st.columns([1,1,1])
with col1:
    pick_step4 = st.selectbox("ÎšÎ±Î½ÏŒÎ½Î±Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÏ„Î¿ Î’Î®Î¼Î± 4", ["best", "first", "strict"], index=0, key="pick_16")
with col2:
    out_name_16 = st.text_input("ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÎµÎ¾ÏŒÎ´Î¿Ï… (1â†’6)", value=_timestamped("STEP1_6_PER_SCENARIO", ".xlsx"))
with col3:
    if up_16 is not None:
        try:
            df_preview2 = pd.read_excel(up_16, sheet_name=0)
            N2 = df_preview2.shape[0]
            min_classes2 = max(2, math.ceil(N2/25)) if N2 else 0
            st.metric("ÎœÎ±Î¸Î·Ï„Î­Ï‚ / Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î± Ï„Î¼Î®Î¼Î±Ï„Î±", f"{N2} / {min_classes2}")
        except Exception:
            st.caption("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·.")

if st.button("ğŸ§ª Î‘ÎÎ‘Î›Î¥Î¤Î™ÎšÎ‘ Î’Î—ÎœÎ‘Î¤Î‘", type="secondary", use_container_width=True):
    last_step6 = st.session_state.get("last_step6_path")
    if last_step6 and Path(last_step6).exists():
        with open(last_step6, "rb") as _f:
            st.download_button("â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Excel (1â†’6)", data=_f.read(), file_name=Path(last_step6).name,
                              mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", use_container_width=True)
        st.stop()
    if missing:
        st.error("Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„Î® Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: Î»ÎµÎ¯Ï€Î¿Ï…Î½ modules.")
    elif up_16 is None:
        st.warning("Î ÏÏÏ„Î± Î±Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Excel.")
    else:
        try:
            input_path = ROOT / _timestamped("INPUT_STEP1", ".xlsx")
            with open(input_path, "wb") as f:
                f.write(up_16.getbuffer())

            m = _load_module("export_step1_6_per_scenario", ROOT / "export_step1_6_per_scenario.py")
            out_path = ROOT / out_name_16

            with st.spinner("Î¤ÏÎ­Ï‡Î¿Ï…Î½ Ï„Î± Î’Î®Î¼Î±Ï„Î± 1â†’6..."):
                m.build_step1_6_per_scenario(str(input_path), str(out_path), pick_step4=pick_step4)

            st.success("âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· Ï€Î±ÏÎ±Î³Ï‰Î³Î® ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ (1â†’6).")
            st.download_button(
                "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Excel (1â†’6)",
                data=_read_file_bytes(out_path),
                file_name=out_path.name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        except Exception as e:
            st.exception(e)