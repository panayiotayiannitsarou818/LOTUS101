# -*- coding: utf-8 -*-
# Wrapper version: 2025-09-06-security-8.6-FEATURES-DOC-and-MATCHING
import re, os, json, importlib.util, datetime as dt, math, base64, unicodedata
from pathlib import Path

import streamlit as st
import pandas as pd
from io import BytesIO

st.set_page_config(page_title="ğŸ§© School Split â€” Thin Wrapper", page_icon="ğŸ§©", layout="wide")
st.title("ğŸ§© School Split â€” Thin Wrapper")
st.caption("Î›ÎµÏ€Ï„ÏŒÏ‚ wrapper ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚ â€” ÎšÎ±Î¼Î¯Î± Î±Î»Î»Î±Î³Î® ÏƒÏ„Î· Î»Î¿Î³Î¹ÎºÎ® Ï„Ï‰Î½ modules.")
st.info("ÎˆÎºÎ´Î¿ÏƒÎ· wrapper: 2025-09-06-security-8.6-FEATURES-DOC-and-MATCHING")

ROOT = Path(__file__).parent
ASSETS = ROOT / "assets"
ASSETS.mkdir(exist_ok=True)
PERSIST_LOGO_PATH = ASSETS / "persisted_logo.bin"
PERSIST_LOGO_META = ASSETS / "persisted_logo.meta.json"

def _load_module(name: str, file_path: Path):
    spec = importlib.util.spec_from_file_location(name, str(file_path))
    mod = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(mod)  # type: ignore
    return mod

def _read_file_bytes(path: Path) -> bytes:
    with open(path, "rb") as f:
        return f.read()

def _timestamped(base: str, ext: str) -> str:
    ts = dt.datetime.now().strftime("%Y%m%d_%H%M%S")
    import re as _re
    safe = _re.sub(r"[^A-Za-z0-9_\-\.]+", "_", base)
    return f"{safe}_{ts}{ext}"

def _check_required_files(paths):
    missing = [str(p) for p in paths if not p.exists()]
    return missing

def _restart_app():
    for k in list(st.session_state.keys()):
        if k.startswith("uploader_") or k in ("auth_ok","accepted_terms","app_enabled","last_final_path"):
            try:
                del st.session_state[k]
            except Exception:
                pass
    try:
        st.cache_data.clear()
    except Exception:
        pass
    try:
        st.cache_resource.clear()
    except Exception:
        pass
    st.rerun()

def _inject_logo(logo_bytes: bytes, width_px: int = 140, mime: str = "image/png"):
    b64 = base64.b64encode(logo_bytes).decode("ascii")
    html = f"""
    <div style="position: fixed; bottom: 38px; right: 38px; z-index: 1000;">
        <img src="data:{mime};base64,{b64}" style="width:{width_px}px; height:auto; opacity:0.95; border-radius:12px;" />
    </div>
    """
    st.markdown(html, unsafe_allow_html=True)

def _terms_md():
    return """
**Î¥Ï€Î¿Ï‡ÏÎµÏ‰Ï„Î¹ÎºÎ® Î‘Ï€Î¿Î´Î¿Ï‡Î® ÎŒÏÏ‰Î½ Î§ÏÎ®ÏƒÎ·Ï‚**  
Î§ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î´Î·Î»ÏÎ½ÎµÏ„Îµ ÏŒÏ„Î¹:  
- Î”ÎµÎ½ Ï„ÏÎ¿Ï€Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Îµ Ï„Î· Î»Î¿Î³Î¹ÎºÎ® Ï„Ï‰Î½ Î±Î»Î³Î¿ÏÎ¯Î¸Î¼Ï‰Î½ ÎºÎ±Î¹ Î´ÎµÎ½ Î±Î½Î±Î´Î¹Î±Î½Î­Î¼ÎµÏ„Îµ Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Ï‡Ï‰ÏÎ¯Ï‚ Î¬Î´ÎµÎ¹Î±.  
- Î‘Î½Î±Î»Î±Î¼Î²Î¬Î½ÎµÏ„Îµ Ï„Î·Î½ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Ï„Î·Î½ Î¿ÏÎ¸ÏŒÏ„Î·Ï„Î± Ï„Ï‰Î½ ÎµÎ¹ÏƒÎ±Î³ÏŒÎ¼ÎµÎ½Ï‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.  
- Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Ï€Î±ÏÎ­Ï‡ÎµÏ„Î±Î¹ Â«Ï‰Ï‚ Î­Ï‡ÎµÎ¹Â», Ï‡Ï‰ÏÎ¯Ï‚ ÎµÎ³Î³ÏÎ·ÏƒÎ· Î³Î¹Î± Î¿Ï€Î¿Î¹Î±Î´Î®Ï€Î¿Ï„Îµ Ï‡ÏÎ®ÏƒÎ·.  

**Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î”Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± & ÎÎ¿Î¼Î¹ÎºÎ® Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î±**  
Â© 2025 Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï… Î Î±Î½Î±Î³Î¹ÏÏ„Î± â€” ÎŒÎ»Î± Ï„Î± Î´Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î± Î´Î¹Î±Ï„Î·ÏÎ¿ÏÎ½Ï„Î±Î¹.  
ÎŸ ÎºÏÎ´Î¹ÎºÎ±Ï‚ wrapper ÎºÎ±Î¹ Ï„Î¿ ÏƒÏ…Î½Î¿Î´ÎµÏ…Ï„Î¹ÎºÏŒ Ï…Î»Î¹ÎºÏŒ Ï€ÏÎ¿ÏƒÏ„Î±Ï„ÎµÏÎ¿Î½Ï„Î±Î¹ Î±Ï€ÏŒ Ï„Î¿ Î´Î¯ÎºÎ±Î¹Î¿ Ï€Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ®Ï‚ Î¹Î´Î¹Î¿ÎºÏ„Î·ÏƒÎ¯Î±Ï‚.  
Î“Î¹Î± Î¬Î´ÎµÎ¹Î± Ï‡ÏÎ®ÏƒÎ·Ï‚/ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯ÎµÏ‚: *panayiotayiannitsarou@gmail.com*.
"""

REQUIRED = [
    ROOT / "export_step1_6_per_scenario.py",
    ROOT / "step1_immutable_ALLINONE.py",
    ROOT / "step_2_helpers_FIXED.py",
    ROOT / "step_2_zoiroi_idiaterotites_FIXED_v3_PATCHED.py",
    ROOT / "step3_amivaia_filia_FIXED.py",
    ROOT / "step4_corrected.py",
    ROOT / "step5_enhanced.py",
    ROOT / "step6_compliant.py",
    ROOT / "step7_fixed_final.py",
]

with st.sidebar:
    st.header("ğŸ” Î ÏÏŒÏƒÎ²Î±ÏƒÎ· & Î¡Ï…Î¸Î¼Î¯ÏƒÎµÎ¹Ï‚")

    st.markdown("**Î‘Ï€Î»Î® ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·/Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚** Ï„Î·Ï‚ ÎºÏÏÎ¹Î±Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚ ÎºÎ±Î¹ ÎºÎ»ÎµÎ¯Î´Ï‰Î¼Î± Î¼Îµ ÎºÏ‰Î´Î¹ÎºÏŒ.")
    pwd = st.text_input("ÎšÏ‰Î´Î¹ÎºÏŒÏ‚ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ·Ï‚", type="password", help="ÎšÏ‰Î´Î¹ÎºÏŒÏ‚: katanomi2025")
    if "auth_ok" not in st.session_state:
        st.session_state.auth_ok = False
    if pwd:
        if pwd.strip() == "katanomi2025":
            st.session_state.auth_ok = True
        else:
            st.session_state.auth_ok = False
            st.error("Î›Î±Î½Î¸Î±ÏƒÎ¼Î­Î½Î¿Ï‚ ÎºÏ‰Î´Î¹ÎºÏŒÏ‚.")

    with st.expander("ğŸ“„ ÎŒÏÎ¿Î¹ Î§ÏÎ®ÏƒÎ·Ï‚ & Î Î½ÎµÏ…Î¼Î±Ï„Î¹ÎºÎ¬ Î”Î¹ÎºÎ±Î¹ÏÎ¼Î±Ï„Î±", expanded=True):
        st.markdown(_terms_md())
    accepted_terms = st.checkbox("âœ… Î‘Ï€Î¿Î´Î­Ï‡Î¿Î¼Î±Î¹ Ï„Î¿Ï…Ï‚ ÎŒÏÎ¿Ï…Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚", value=st.session_state.get("accepted_terms", False))
    st.session_state.accepted_terms = accepted_terms

    app_enabled = st.toggle("â¯ï¸ Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¯Î·ÏƒÎ· ÎºÏÏÎ¹Î±Ï‚ ÎµÏ†Î±ÏÎ¼Î¿Î³Î®Ï‚", value=st.session_state.get("app_enabled", True))
    st.session_state.app_enabled = app_enabled

    st.divider()
    st.subheader("ğŸ–¼ï¸ Î›Î¿Î³ÏŒÏ„Ï…Ï€Î¿")

    if PERSIST_LOGO_PATH.exists() and PERSIST_LOGO_META.exists():
        try:
            meta = json.loads(PERSIST_LOGO_META.read_text(encoding="utf-8"))
            mime = meta.get("mime", "image/png")
            _inject_logo(_read_file_bytes(PERSIST_LOGO_PATH), width_px=140, mime=mime)
            st.caption("Î¦Î¿ÏÏ„ÏÎ¸Î·ÎºÎµ **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±** Ï„Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ (ÎºÎ¬Ï„Ï‰ Î´ÎµÎ¾Î¹Î¬).")
        except Exception:
            st.warning("Î¤Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ Î´ÎµÎ½ Î¼Ï€ÏŒÏÎµÏƒÎµ Î½Î± Ï†Î¿ÏÏ„Ï‰Î¸ÎµÎ¯.")

    logo_file = st.file_uploader("PNG/JPG/SVG Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÏŒ)", type=["png","jpg","jpeg","svg"], key="logo_upl")
    if logo_file is not None:
        try:
            mime = getattr(logo_file, "type", "image/png") or "image/png"
            data = logo_file.read()
            _inject_logo(data, width_px=140, mime=mime)
            try:
                PERSIST_LOGO_PATH.write_bytes(data)
                PERSIST_LOGO_META.write_text(json.dumps({"mime": mime, "saved_at": dt.datetime.now().isoformat()}), encoding="utf-8")
                st.success("Î¤Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ **Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î¼ÏŒÎ½Î¹Î¼Î±** ÎºÎ±Î¹ Î¸Î± Ï†Î¿ÏÏ„ÏÎ½ÎµÏ„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±.")
            except Exception as e:
                st.warning(f"Î‘Î½ÎµÎ²Î¬ÏƒÏ„Î·ÎºÎµ, Î±Î»Î»Î¬ Î´ÎµÎ½ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ Î¼ÏŒÎ½Î¹Î¼Î±: {e}")
        except Exception:
            st.warning("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· ÎµÎ¼Ï†Î¬Î½Î¹ÏƒÎ· Ï„Î¿Ï… Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿Ï….")

    colL, colR = st.columns([1,1])
    with colL:
        if st.button("ğŸ§¹ ÎšÎ±Î¸Î±ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿Ï… Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿Ï…", use_container_width=True):
            try:
                if PERSIST_LOGO_PATH.exists(): PERSIST_LOGO_PATH.unlink()
                if PERSIST_LOGO_META.exists(): PERSIST_LOGO_META.unlink()
                st.success("Î”Î¹Î±Î³ÏÎ¬Ï†Î·ÎºÎµ Ï„Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿.")
                st.experimental_rerun()
            except Exception as e:
                st.error(f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± ÎºÎ±Î¸Î±ÏÎ¹ÏƒÎ¼Î¿Ï: {e}")
    with colR:
        st.caption("Î¤Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏ…Î¼Î­Î½Î¿ Î»Î¿Î³ÏŒÏ„Ï…Ï€Î¿ Ï†Î¿ÏÏ„ÏÎ½ÎµÏ„Î±Î¹ Ï€Î¬Î½Ï„Î± Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±.")

with st.expander("â„¹ï¸ Î•Î³Ï‡ÎµÎ¹ÏÎ¯Î´Î¹Î¿ / Î§Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬", expanded=True):
    st.markdown("""
**ÎšÏÏÎ¹Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î±**  
- ğŸ“Š *Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ Î±Î½Î¬ Ï„Î¼Î®Î¼Î±:* ÎšÎ±Ï„Î±Î½Î¿Î¼Î® Ï†ÏÎ»Î¿Ï… (Î±Î³ÏŒÏÎ¹Î±/ÎºÎ¿ÏÎ¯Ï„ÏƒÎ¹Î±), Î Î±Î¹Î´Î¹Î¬ ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ¿Ï, Î–Ï‰Î·ÏÎ¬, Î™Î´Î¹Î±Î¹Ï„ÎµÏÏŒÏ„Î·Ï„ÎµÏ‚, Î•Ï€Î¯Ï€ÎµÎ´Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÏÎ½, ÎœÎµÏ„ÏÎ·Ï„Î­Ï‚ ÏƒÏ…Î³ÎºÏÎ¿ÏÏƒÎµÏ‰Î½ & ÏƒÏ€Î±ÏƒÎ¼Î­Î½Ï‰Î½ Ï†Î¹Î»Î¹ÏÎ½.  
- ğŸ§© *Î‘Î½Î¬Î»Ï…ÏƒÎ· ÏƒÏ€Î±ÏƒÎ¼Î­Î½Ï‰Î½ Î±Î¼Î¿Î¹Î²Î±Î¯Ï‰Î½ Ï†Î¹Î»Î¹ÏÎ½:* Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î¼Î±Î¸Î·Ï„ÏÎ½ Ï€Î¿Ï… Î´Î·Î»ÏÎ½Î¿Ï…Î½ Î±Î¼Î¿Î¹Î²Î±Î¯Î± Ï†Î¹Î»Î¯Î± Î±Î»Î»Î¬ ÎµÎ¯Î½Î±Î¹ ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Ï„Î¼Î®Î¼Î±Ï„Î±, Ï€Î±ÏÎ±Î³Ï‰Î³Î® Î±Î½Î±Ï†Î¿ÏÏÎ½ (Ï€Î»Î®ÏÎ·Ï‚ Î»Î¯ÏƒÏ„Î± Î¶ÎµÏ…Î³ÏÎ½ & Î¼ÎµÏ„ÏÎ·Ï„Î­Ï‚ Î±Î½Î¬ Î¼Î±Î¸Î·Ï„Î®).  
- ğŸ§¾ *Î£Ï…Î³ÎºÏÎ¿ÏÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ Î¯Î´Î¹Î¿ Ï„Î¼Î®Î¼Î±:* Î•Î½Ï„Î¿Ï€Î¹ÏƒÎ¼ÏŒÏ‚ Î¼Î±Î¸Î·Ï„ÏÎ½ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· Î¼Îµ ÏƒÏ…Î¼Î¼Î±Î¸Î·Ï„Î­Ï‚ Ï„Î¿Ï… Î¯Î´Î¹Î¿Ï… Ï„Î¼Î®Î¼Î±Ï„Î¿Ï‚ (Î¼ÎµÏ„ÏÎ·Ï„Î­Ï‚ & Î¿Î½ÏŒÎ¼Î±Ï„Î±).  

**Î¤ÎµÏ‡Î½Î¹ÎºÎ¬ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬**  
- *Auto-rename columns:* ÎˆÎ¾Ï…Ï€Î½Î· Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· ÎµÎ»Î»Î·Î½Î¹ÎºÏÎ½ ÏƒÏ„Î·Î»ÏÎ½ ÏƒÎµ ÎºÎ±Î½Î¿Î½Î¹ÎºÎ® Î¼Î¿ÏÏ†Î®.  
- *Name canonicalization:* Î‘Ï†Î±Î¯ÏÎµÏƒÎ· Î´Î¹Î±ÎºÏÎ¹Ï„Î¹ÎºÏÎ½, normalization Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½.  
- *Friends parsing:* Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î»Î¹ÏƒÏ„ÏÎ½ Ï†Î¯Î»Ï‰Î½ (CSV, arrays, Îº.Î»Ï€.).  
- *Token-based name resolution:* Î•Ï…Ï†Ï…Î®Ï‚ Î±Î½Ï„Î¹ÏƒÏ„Î¿Î¯Ï‡Î¹ÏƒÎ· Î¿Î½Î¿Î¼Î¬Ï„Ï‰Î½ Î¼Îµ partial matching.  
- *Multi-sheet processing:* Î‘Î½Î¬Î»Ï…ÏƒÎ· Ï€Î¿Î»Î»Î±Ï€Î»ÏÎ½ ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½/Ï„Î¼Î·Î¼Î¬Ï„Ï‰Î½ (ÏŒÏ€Î¿Ï… Î´Î¹Î±Ï„Î¯Î¸ÎµÏ„Î±Î¹).  
- *Excel export:* Î Î»Î®ÏÎµÎ¹Ï‚ Î±Î½Î±Ï†Î¿ÏÎ­Ï‚ Î¼Îµ formatting.  

**Î£Ï…Î¼Î¼ÏŒÏÏ†Ï‰ÏƒÎ·**  
- GDPR notices ÎºÎ±Î¹ ÏŒÏÎ¿Î¹ Ï‡ÏÎ®ÏƒÎ·Ï‚ â€” ÎµÎºÏ€Î±Î¹Î´ÎµÏ…Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ· Î¼ÏŒÎ½Î¿.  
- Î ÏÎ¿ÏƒÏ„Î±ÏƒÎ¯Î± Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÏÎ½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½.  
- Copyright notice: Â© 2025 Î“Î¹Î±Î½Î½Î¯Ï„ÏƒÎ±ÏÎ¿Ï… Î Î±Î½Î±Î³Î¹ÏÏ„Î±.
""")

# Î ÏÎ»ÎµÏ‚
if not st.session_state.auth_ok:
    st.warning("ğŸ” Î•Î¹ÏƒÎ¬Î³ÎµÏ„Îµ Ï„Î¿Î½ ÏƒÏ‰ÏƒÏ„ÏŒ ÎºÏ‰Î´Î¹ÎºÏŒ Î³Î¹Î± Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· (katanomi2025).")
    st.stop()

if not st.session_state.accepted_terms:
    st.warning("âœ… Î“Î¹Î± Î½Î± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÎµÏ„Îµ, Î±Ï€Î¿Î´ÎµÏ‡Î¸ÎµÎ¯Ï„Îµ Ï„Î¿Ï…Ï‚ ÎŒÏÎ¿Ï…Ï‚ Î§ÏÎ®ÏƒÎ·Ï‚ (Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬).")
    st.stop()

if not st.session_state.app_enabled:
    st.info("â¸ï¸ Î— ÎµÏ†Î±ÏÎ¼Î¿Î³Î® ÎµÎ¯Î½Î±Î¹ Î±Ï€ÎµÎ½ÎµÏÎ³Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î·. Î•Î½ÎµÏÎ³Î¿Ï€Î¿Î¹Î®ÏƒÏ„Îµ Ï„Î·Î½ Î±Ï€ÏŒ Ï„Î± Î±ÏÎ¹ÏƒÏ„ÎµÏÎ¬.")
    st.stop()

# ===== ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½ =====
st.subheader("ğŸ“¦ ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±ÏÏ‡ÎµÎ¯Ï‰Î½")
missing = _check_required_files(REQUIRED)
if missing:
    st.error("âŒ Î›ÎµÎ¯Ï€Î¿Ï…Î½ Î±ÏÏ‡ÎµÎ¯Î±:\n" + "\n".join(f"- {m }" for m in missing))
else:
    st.success("âœ… ÎŒÎ»Î± Ï„Î± Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± Î±ÏÏ‡ÎµÎ¯Î± Î²ÏÎ­Î¸Î·ÎºÎ±Î½.")

st.divider()

# ===== Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£ (1â†’7) =====
st.header("ğŸš€ Î•ÎºÏ„Î­Î»ÎµÏƒÎ· ÎŸÎ›Î‘ (Î’Î®Î¼Î±Ï„Î± 1â†’7)")
st.write("Î‘Î½Î­Î²Î±ÏƒÎµ Î¼ÏŒÎ½Î¿ Ï„Î¿ **Î±ÏÏ‡Î¹ÎºÏŒ Excel**. ÎŸ wrapper Ï„ÏÎ­Ï‡ÎµÎ¹ 1â†’6 ÎºÎ±Î¹ Î¼ÎµÏ„Î¬ 7 ÎºÎ±Î¹ Î´Î¯Î½ÎµÎ¹ **Ï„ÎµÎ»Î¹ÎºÏŒ Î±Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î±**. Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÎµÏ„Î±Î¹ ÎºÎ±Î¹ Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î± Î±Ï€ÏŒ Ï„Î± Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬.")

up_all = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ Î±ÏÏ‡Î¹ÎºÏŒ Excel (Î³Î¹Î± 1â†’7)", type=["xlsx"], key="uploader_all")
colA, colB, colC = st.columns([1,1,1])
with colA:
    pick_step4_all = st.selectbox("ÎšÎ±Î½ÏŒÎ½Î±Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÏ„Î¿ Î’Î®Î¼Î± 4", ["best", "first", "strict"], index=0, key="pick_all")
with colB:
    final_name_all = st.text_input("ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… Î¤ÎµÎ»Î¹ÎºÎ¿Ï Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î¿Ï‚", value=_timestamped("STEP7_FINAL_SCENARIO", ".xlsx"))
with colC:
    if up_all is not None:
        try:
            df_preview = pd.read_excel(up_all, sheet_name=0)
            N = df_preview.shape[0]
            min_classes = max(2, math.ceil(N/25)) if N else 0
            st.metric("ÎœÎ±Î¸Î·Ï„Î­Ï‚ / Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î± Ï„Î¼Î®Î¼Î±Ï„Î±", f"{N} / {min_classes}")
        except Exception:
            st.caption("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·.")

run_all = st.button("ğŸš€ Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£", type="primary", use_container_width=True)

if run_all:
    if missing:
        st.error("Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„Î® Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: Î»ÎµÎ¯Ï€Î¿Ï…Î½ modules.")
    elif up_all is None:
        st.warning("Î ÏÏÏ„Î± Î±Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Excel.")
    else:
        try:
            input_path = ROOT / _timestamped("INPUT_STEP1", ".xlsx")
            with open(input_path, "wb") as f:
                f.write(up_all.getbuffer())

            m = _load_module("export_step1_6_per_scenario", ROOT / "export_step1_6_per_scenario.py")
            s7 = _load_module("step7_fixed_final", ROOT / "step7_fixed_final.py")

            step6_path = ROOT / _timestamped("STEP1_6_PER_SCENARIO", ".xlsx")
            with st.spinner("Î¤ÏÎ­Ï‡Î¿Ï…Î½ Ï„Î± Î’Î®Î¼Î±Ï„Î± 1â†’6..."):
                m.build_step1_6_per_scenario(str(input_path), str(step6_path), pick_step4=pick_step4_all)

            with st.spinner("Î¤ÏÎ­Ï‡ÎµÎ¹ Ï„Î¿ Î’Î®Î¼Î± 7..."):
                xls = pd.ExcelFile(step6_path)
                sheet_names = [s for s in xls.sheet_names if s != "Î£ÏÎ½Î¿ÏˆÎ·"]
                if not sheet_names:
                    st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ sheets ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ (ÎµÎºÏ„ÏŒÏ‚ Î±Ï€ÏŒ 'Î£ÏÎ½Î¿ÏˆÎ·').")
                else:
                    df0 = pd.read_excel(step6_path, sheet_name=sheet_names[0])
                    scen_cols = [c for c in df0.columns if re.match(r"^Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_\d+$", str(c))]
                    if not scen_cols:
                        st.error("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ„Î®Î»ÎµÏ‚ Ï„ÏÏ€Î¿Ï… 'Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_N'.")
                    else:
                        pick = s7.pick_best_scenario(df0.copy(), scen_cols, random_seed=42)
                        best = pick.get("best")
                        if not best or "scenario_col" not in best:
                            st.error("Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÎµÎ½Î±ÏÎ¯Î¿Ï….")
                        else:
                            winning_col = best["scenario_col"]
                            final_out = ROOT / final_name_all
                            full_df = pd.read_excel(step6_path, sheet_name=sheet_names[0]).copy()
                            with pd.ExcelWriter(final_out, engine="xlsxwriter") as w:
                                full_df.to_excel(w, index=False, sheet_name="FINAL_SCENARIO")
                                labels = sorted(
                                    [str(v) for v in full_df[winning_col].dropna().unique() if re.match(r"^Î‘\d+$", str(v))],
                                    key=lambda x: int(re.search(r"\d+", x).group(0))
                                )
                                for lab in labels:
                                    sub = full_df.loc[full_df[winning_col] == lab, ["ÎŸÎÎŸÎœÎ‘", winning_col]].copy()
                                    sub = sub.rename(columns={winning_col: "Î¤ÎœÎ—ÎœÎ‘"})
                                    sub.to_excel(w, index=False, sheet_name=str(lab))

                            st.session_state["last_final_path"] = str(final_out.resolve())

                            st.success(f"âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ. ÎÎ¹ÎºÎ·Ï„Î®Ï‚: ÏƒÏ„Î®Î»Î· {winning_col}")
                            st.download_button(
                                "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Î¤ÎµÎ»Î¹ÎºÏŒ Î‘Ï€Î¿Ï„Î­Î»ÎµÏƒÎ¼Î± (1â†’7)",
                                data=_read_file_bytes(final_out),
                                file_name=final_out.name,
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                            st.caption("â„¹ï¸ Î¤Î¿ Î±ÏÏ‡ÎµÎ¯Î¿ Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎµ ÎºÎ±Î¹ Î¸Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹Î·Î¸ÎµÎ¯ **Î±Ï…Ï„ÏŒÎ¼Î±Ï„Î±** Î±Ï€ÏŒ Ï„Î± Â«ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬Â».")

        except Exception as e:
            st.exception(e)

st.divider()

# ===== Helpers (stats) =====
def _find_latest_final_path() -> Path | None:
    p = st.session_state.get("last_final_path")
    if p and Path(p).exists():
        return Path(p)
    candidates = list(ROOT.glob("STEP7_FINAL_SCENARIO*.xlsx"))
    if not candidates:
        return None
    candidates.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return candidates[0]

def _strip_diacritics(s: str) -> str:
    nfkd = unicodedata.normalize("NFD", s)
    return "".join(ch for ch in nfkd if not unicodedata.combining(ch))

def _canon_name(s: str) -> str:
    s = (str(s) if s is not None else "").strip()
    s = s.strip("[]'\" ")
    s = re.sub(r"\s+", " ", s)
    s = _strip_diacritics(s).upper()
    return s

def _tokenize_name(canon: str):
    return [t for t in re.split(r"[^A-Z0-9]+", canon) if t]

def _best_name_match(target_canon: str, candidates: list[str]) -> str | None:
    # Exact
    if target_canon in candidates:
        return target_canon
    tks = set(_tokenize_name(target_canon))
    if not tks:
        return None
    # Score by token overlap and prefix hits
    best = None; best_score = 0.0
    for c in candidates:
        cks = set(_tokenize_name(c))
        if not cks:
            continue
        inter = tks & cks
        jacc = len(inter) / max(1, len(tks | cks))
        prefix = any(c.startswith(tok) or target_canon.startswith(tok) for tok in inter) if inter else False
        score = jacc + (0.2 if prefix else 0.0)
        if score > best_score:
            best = c; best_score = score
    if best_score >= 0.34:  # conservative threshold
        return best
    return None

def auto_rename_columns(df: pd.DataFrame):
    mapping = {}
    if "Î¦Î™Î›ÎŸÎ™" not in df.columns:
        for c in df.columns:
            if "Î¦Î™Î›" in str(c).upper():
                mapping[c] = "Î¦Î™Î›ÎŸÎ™"
                break
    if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" not in df.columns and "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£" in df.columns:
        mapping["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î•Î™Î£"] = "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—"
    return df.rename(columns=mapping), mapping

def compute_conflict_counts_and_names(df: pd.DataFrame):
    if "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
        return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)
    # Ensure Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î— column exists
    sc = "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" if "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—" in df.columns else None
    if sc is None:
        return pd.Series([0]*len(df), index=df.index), pd.Series([""]*len(df), index=df.index)
    df = df.copy()
    df["__C"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
    cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
    canon_names = list(df["__C"].astype(str).unique())
    index_by = {cn: i for i, cn in enumerate(df["__C"])}
    def parse_targets(cell):
        raw = str(cell) if cell is not None else ""
        parts = [p.strip() for p in re.split(r"[;,/|\n]", raw) if p.strip()]
        return [_canon_name(p) for p in parts]
    counts = [0]*len(df); names = [""]*len(df)
    for i, row in df.iterrows():
        my_class = cls.iloc[i]
        targets = parse_targets(row.get(sc,""))
        same = []
        for t in targets:
            j = index_by.get(t)
            if j is None:
                # try best-match
                match = _best_name_match(t, canon_names)
                j = index_by.get(match) if match else None
            if j is not None and cls.iloc[j] == my_class and df.loc[i, "__C"] != df.loc[j, "__C"]:
                same.append(df.loc[j, "ÎŸÎÎŸÎœÎ‘"])
        counts[i] = len(same)
        names[i] = ", ".join(same)
    return pd.Series(counts, index=df.index), pd.Series(names, index=df.index)

def list_broken_mutual_pairs(df: pd.DataFrame) -> pd.DataFrame:
    fcol = next((c for c in ["Î¦Î™Î›ÎŸÎ™","Î¦Î™Î›ÎŸÎ£","Î¦Î™Î›Î™Î‘"] if c in df.columns), None)
    if fcol is None or "ÎŸÎÎŸÎœÎ‘" not in df.columns or "Î¤ÎœÎ—ÎœÎ‘" not in df.columns:
        return pd.DataFrame(columns=["A","A_Î¤ÎœÎ—ÎœÎ‘","B","B_Î¤ÎœÎ—ÎœÎ‘"])
    df = df.copy()
    df["__C"] = df["ÎŸÎÎŸÎœÎ‘"].map(_canon_name)
    name_to_original = dict(zip(df["__C"], df["ÎŸÎÎŸÎœÎ‘"].astype(str)))
    class_by_name = dict(zip(df["__C"], df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()))
    canon_names = list(df["__C"].astype(str).unique())
    def parse_list(cell):
        raw = str(cell) if cell is not None else ""
        parts = [p.strip() for p in re.split(r"[;,/|\n]", raw) if p.strip()]
        return [_canon_name(p) for p in parts]
    friends_map = {}
    for i, cn in enumerate(df["__C"]):
        raw_targets = parse_list(df.loc[i, fcol])
        resolved = []
        for t in raw_targets:
            if t in canon_names:
                resolved.append(t)
            else:
                match = _best_name_match(t, canon_names)
                if match:
                    resolved.append(match)
        friends_map[cn] = set(resolved)
    rows = []
    for a, fa in friends_map.items():
        for b in fa:
            fb = friends_map.get(b, set())
            if a in fb and class_by_name.get(a) != class_by_name.get(b):
                rows.append({
                    "A": name_to_original.get(a, a), "A_Î¤ÎœÎ—ÎœÎ‘": class_by_name.get(a,""),
                    "B": name_to_original.get(b, b), "B_Î¤ÎœÎ—ÎœÎ‘": class_by_name.get(b,"")
                })
    return pd.DataFrame(rows).drop_duplicates()

def generate_stats(df: pd.DataFrame) -> pd.DataFrame:
    df = df.copy()
    if "Î¤ÎœÎ—ÎœÎ‘" in df:
        df["Î¤ÎœÎ—ÎœÎ‘"] = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
    boys = df[df.get("Î¦Î¥Î›ÎŸ","").astype(str).str.upper().eq("Î‘")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
    girls = df[df.get("Î¦Î¥Î›ÎŸ","").astype(str).str.upper().eq("Îš")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¦Î¥Î›ÎŸ" in df else pd.Series(dtype=int)
    edus = df[df.get("Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥" in df else pd.Series(dtype=int)
    z = df[df.get("Î–Î©Î—Î¡ÎŸÎ£","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î–Î©Î—Î¡ÎŸÎ£" in df else pd.Series(dtype=int)
    id_ = df[df.get("Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘" in df else pd.Series(dtype=int)
    g = df[df.get("ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","").astype(str).str.upper().eq("Î")].groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î" in df else pd.Series(dtype=int)
    total = df.groupby("Î¤ÎœÎ—ÎœÎ‘").size() if "Î¤ÎœÎ—ÎœÎ‘" in df else pd.Series(dtype=int)

    try:
        c_counts, _ = compute_conflict_counts_and_names(df)
        cls = df["Î¤ÎœÎ—ÎœÎ‘"].astype(str).str.strip()
        conf_by_class = c_counts.groupby(cls).sum().astype(int)
    except Exception:
        conf_by_class = pd.Series(dtype=int)

    try:
        pairs = list_broken_mutual_pairs(df)
        if pairs.empty:
            broken = pd.Series({tm: 0 for tm in df["Î¤ÎœÎ—ÎœÎ‘"].dropna().astype(str).str.strip().unique()})
        else:
            counts = {}
            for _, row in pairs.iterrows():
                counts[row["A_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["A_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                counts[row["B_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["B_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
            broken = pd.Series(counts).astype(int)
    except Exception:
        broken = pd.Series(dtype=int)

    stats = pd.DataFrame({
        "Î‘Î“ÎŸÎ¡Î™Î‘": boys,
        "ÎšÎŸÎ¡Î™Î¤Î£Î™Î‘": girls,
        "Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥": edus,
        "Î–Î©Î—Î¡ÎŸÎ™": z,
        "Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘": id_,
        "Î“ÎÎ©Î£Î— Î•Î›Î›Î—ÎÎ™ÎšÎ©Î": g,
        "Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—": conf_by_class,
        "Î£Î Î‘Î£ÎœÎ•ÎÎ— Î¦Î™Î›Î™Î‘": broken,
        "Î£Î¥ÎÎŸÎ›ÎŸ ÎœÎ‘Î˜Î—Î¤Î©Î": total,
    }).fillna(0).astype(int)

    try:
        stats = stats.sort_index(key=lambda x: x.str.extract(r"(\d+)")[0].astype(float))
    except Exception:
        stats = stats.sort_index()
    return stats

def export_stats_to_excel(stats_df: pd.DataFrame) -> BytesIO:
    output = BytesIO()
    with pd.ExcelWriter(output, engine="xlsxwriter") as writer:
        stats_df.to_excel(writer, index=True, sheet_name="Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬", index_label="Î¤ÎœÎ—ÎœÎ‘")
        wb = writer.book; ws = writer.sheets["Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬"]
        header_fmt = wb.add_format({"bold": True, "valign":"vcenter", "text_wrap": True, "border":1})
        for col_idx, value in enumerate(["Î¤ÎœÎ—ÎœÎ‘"] + list(stats_df.columns)):
            ws.write(0, col_idx, value, header_fmt)
        for i in range(0, len(stats_df.columns)+1):
            ws.set_column(i, i, 18)
    output.seek(0)
    return output

def prepare_conflict_students(df: pd.DataFrame) -> pd.DataFrame:
    counts, names = compute_conflict_counts_and_names(df)
    out = df.copy()
    out["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£"] = counts.astype(int)
    out["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"] = names
    out = out.loc[out["Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£"] > 0, ["ÎŸÎÎŸÎœÎ‘","Î¤ÎœÎ—ÎœÎ‘","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_Î Î›Î—Î˜ÎŸÎ£","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—_ÎŸÎÎŸÎœÎ‘"]]
    return out.sort_values(["Î¤ÎœÎ—ÎœÎ‘","ÎŸÎÎŸÎœÎ‘"])

# ===== ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ â€” UI tabs =====
st.header("ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ â€” Î‘Î¥Î£Î¤Î—Î¡Î‘ (AUTO Î±Ï€ÏŒ Î’Î®Î¼Î± 7)")

def _find_latest_final_path() -> Path | None:
    p = st.session_state.get("last_final_path")
    if p and Path(p).exists():
        return Path(p)
    candidates = list(ROOT.glob("STEP7_FINAL_SCENARIO*.xlsx"))
    if not candidates:
        return None
    candidates.sort(key=lambda x: x.stat().st_mtime, reverse=True)
    return candidates[0]

final_path = _find_latest_final_path()
if not final_path:
    st.warning("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎµ Î±ÏÏ‡ÎµÎ¯Î¿ Î’Î®Î¼Î±Ï„Î¿Ï‚ 7. Î ÏÏÏ„Î± Ï„ÏÎ­Î¾Îµ Â«Î•ÎšÎ¤Î•Î›Î•Î£Î— ÎšÎ‘Î¤Î‘ÎÎŸÎœÎ—Î£Â».")
else:
    try:
        xl = pd.ExcelFile(final_path)
        sheets = xl.sheet_names
        st.success(f"âœ… Î’ÏÎ­Î¸Î·ÎºÎµ: **{final_path.name}** | Sheets: {', '.join(sheets)}")
    except Exception as e:
        xl = None
        st.error(f"âŒ Î£Ï†Î¬Î»Î¼Î± Î±Î½Î¬Î³Î½Ï‰ÏƒÎ·Ï‚: {e}")

    if xl is not None and "FINAL_SCENARIO" in sheets:
        used_df = xl.parse("FINAL_SCENARIO")
        scen_cols = [c for c in used_df.columns if re.match(r"^Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_\d+$", str(c))]
        if len(scen_cols) != 1:
            st.error("âŒ Î‘Ï€Î±Î¹Ï„ÎµÎ¯Ï„Î±Î¹ **Î±ÎºÏÎ¹Î²ÏÏ‚ Î¼Î¯Î±** ÏƒÏ„Î®Î»Î· `Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_N` ÏƒÏ„Î¿ FINAL_SCENARIO.")
        else:
            used_df["Î¤ÎœÎ—ÎœÎ‘"] = used_df[scen_cols[0]].astype(str).str.strip()
            used_df, rename_map = auto_rename_columns(used_df)

            tab1, tab2, tab3 = st.tabs([
                "ğŸ“Š Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÎ¬ (1 sheet)",
                "âŒ Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ (ÏŒÎ»Î± Ï„Î± sheets) â€” ÎˆÎ¾Î¿Î´Î¿Ï‚: Î Î»Î®ÏÎµÏ‚ Î±Î½Ï„Î¯Î³ÏÎ±Ï†Î¿ + Î£ÏÎ½Î¿ÏˆÎ·",
                "âš ï¸ ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î·",
            ])

            with tab1:
                st.subheader("ğŸ“ˆ Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ Î³Î¹Î± Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿ Sheet")
                sheet_choice = st.selectbox("Î”Î¹Î¬Î»ÎµÎ¾Îµ sheet", ["FINAL_SCENARIO"])

                with st.expander("ğŸ” Î”Î¹Î¬Î³Î½Ï‰ÏƒÎ·/ÎœÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚", expanded=False):
                    st.write("Î‘Ï…Ï„ÏŒÎ¼Î±Ï„ÎµÏ‚ Î¼ÎµÏ„Î¿Î½Î¿Î¼Î±ÏƒÎ¯ÎµÏ‚:", rename_map if rename_map else "â€”")
                    required_cols = ["ÎŸÎÎŸÎœÎ‘","Î¦Î¥Î›ÎŸ","Î Î‘Î™Î”Î™_Î•ÎšÎ Î‘Î™Î”Î•Î¥Î¤Î™ÎšÎŸÎ¥","Î–Î©Î—Î¡ÎŸÎ£","Î™Î”Î™Î‘Î™Î¤Î•Î¡ÎŸÎ¤Î—Î¤Î‘","ÎšÎ‘Î›Î—_Î“ÎÎ©Î£Î—_Î•Î›Î›Î—ÎÎ™ÎšÎ©Î","Î¦Î™Î›ÎŸÎ™","Î£Î¥Î“ÎšÎ¡ÎŸÎ¥Î£Î—",]
                    missing_cols = [c for c in required_cols if c not in used_df.columns]
                    st.write("Î›ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î®Î»ÎµÏ‚:", missing_cols if missing_cols else "â€”")
                st.info("Î£Ï…Î¼Ï€Î»Î®ÏÏ‰ÏƒÎµ/Î´Î¹ÏŒÏÎ¸Ï‰ÏƒÎµ Ï„Î¹Ï‚ ÏƒÏ„Î®Î»ÎµÏ‚ Ï€Î¿Ï… Î»ÎµÎ¯Ï€Î¿Ï…Î½ ÏƒÏ„Î¿ Excel ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†ÏŒÏÏ„Ï‰ÏƒÎ­ Ï„Î¿.")

                stats_df = generate_stats(used_df)
                st.dataframe(stats_df, use_container_width=True)

                st.download_button(
                    "ğŸ“¥ Î•Î¾Î±Î³Ï‰Î³Î® ÎœÎŸÎÎŸ Î£Ï„Î±Ï„Î¹ÏƒÏ„Î¹ÎºÏÎ½ (Excel)",
                    data=export_stats_to_excel(stats_df).getvalue(),
                    file_name=f"statistika_STEP7_FINAL_UI_{dt.datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                    type="primary"
                )

            with tab2:
                st.subheader("ğŸ’” Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚")
                pairs = list_broken_mutual_pairs(used_df)
                if pairs.empty:
                    st.success("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î±Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚ Ï†Î¹Î»Î¯ÎµÏ‚.")
                else:
                    st.dataframe(pairs, use_container_width=True)
                    counts = {}
                    for _, row in pairs.iterrows():
                        counts[row["A_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["A_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                        counts[row["B_Î¤ÎœÎ—ÎœÎ‘"]] = counts.get(row["B_Î¤ÎœÎ—ÎœÎ‘"], 0) + 1
                    summary = pd.DataFrame.from_dict(counts, orient="index", columns=["Î£Ï€Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Î‘Î¼Î¿Î¹Î²Î±Î¯ÎµÏ‚"]).sort_index()
                    st.write("Î£ÏÎ½Î¿ÏˆÎ· Î±Î½Î¬ Ï„Î¼Î®Î¼Î±:")
                    st.dataframe(summary, use_container_width=True)

            with tab3:
                st.subheader("âš ï¸ ÎœÎ±Î¸Î·Ï„Î­Ï‚ Î¼Îµ ÏƒÏÎ³ÎºÏÎ¿Ï…ÏƒÎ· ÏƒÏ„Î·Î½ Î¯Î´Î¹Î± Ï„Î¬Î¾Î·")
                conflict_students = prepare_conflict_students(used_df)
                if conflict_students.empty:
                    st.success("Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ ÏƒÏ…Î³ÎºÏÎ¿ÏÏƒÎµÎ¹Ï‚ ÎµÎ½Ï„ÏŒÏ‚ Ï„Î·Ï‚ Î¯Î´Î¹Î±Ï‚ Ï„Î¬Î¾Î·Ï‚.")
                else:
                    st.dataframe(conflict_students, use_container_width=True)

st.divider()

# ===== â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· (Î¼Î¯Î± ÎºÎ±Î¹ ÎºÎ±Î»Î®) =====
st.header("â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ·")
st.write("ÎšÎ±Î¸Î±ÏÎ¯Î¶ÎµÎ¹ Ï€ÏÎ¿ÏƒÏ‰ÏÎ¹Î½Î¬ Î´ÎµÎ´Î¿Î¼Î­Î½Î± ÎºÎ±Î¹ Î¾Î±Î½Î±Ï†Î¿ÏÏ„ÏÎ½ÎµÎ¹ Ï„Î¿ app.")
if st.button("â™»ï¸ Î•Ï€Î±Î½ÎµÎºÎºÎ¯Î½Î·ÏƒÎ· Ï„ÏÏÎ±", type="secondary", use_container_width=True, key="restart_btn"):
    _restart_app()

st.divider()

# ===== ğŸ” Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ (1â†’6) â€” Î¤Î•Î›Î•Î¥Î¤Î‘Î™ÎŸ =====
st.header("ğŸ” Î‘Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ Î£ÎµÎ½Î¬ÏÎ¹Î± (Î’Î®Î¼Î±Ï„Î± 1â†’6)")
st.write("Î•Î½ÏŒÏ„Î·Ï„Î± ÏƒÏ€Î¬Î½Î¹Î±Ï‚ Ï‡ÏÎ®ÏƒÎ·Ï‚, Î¼ÏŒÎ½Î¿ Î³Î¹Î± Î­Î»ÎµÎ³Ï‡Î¿: Ï€Î±ÏÎ¬Î³ÎµÎ¹ Excel Î¼Îµ ÏŒÎ»Î± Ï„Î± ÏƒÎµÎ½Î¬ÏÎ¹Î± (Î’Î—ÎœÎ‘6_Î£Î•ÎÎ‘Î¡Î™ÎŸ_1, â€¦) ÎºÎ±Î¹ ÏƒÏÎ½Î¿ÏˆÎ·.")

up_16 = st.file_uploader("Î‘Î½Î­Î²Î±ÏƒÎµ Î±ÏÏ‡Î¹ÎºÏŒ Excel (Î³Î¹Î± 1â†’6)", type=["xlsx"], key="uploader_16")
col1, col2, col3 = st.columns([1,1,1])
with col1:
    pick_step4 = st.selectbox("ÎšÎ±Î½ÏŒÎ½Î±Ï‚ ÎµÏ€Î¹Î»Î¿Î³Î®Ï‚ ÏƒÏ„Î¿ Î’Î®Î¼Î± 4", ["best", "first", "strict"], index=0, key="pick_16")
with col2:
    out_name_16 = st.text_input("ÎŒÎ½Î¿Î¼Î± Î±ÏÏ‡ÎµÎ¯Î¿Ï… ÎµÎ¾ÏŒÎ´Î¿Ï… (1â†’6)", value=_timestamped("STEP1_6_PER_SCENARIO", ".xlsx"))
with col3:
    if up_16 is not None:
        try:
            df_preview2 = pd.read_excel(up_16, sheet_name=0)
            N2 = df_preview2.shape[0]
            min_classes2 = max(2, math.ceil(N2/25)) if N2 else 0
            st.metric("ÎœÎ±Î¸Î·Ï„Î­Ï‚ / Î•Î»Î¬Ï‡Î¹ÏƒÏ„Î± Ï„Î¼Î®Î¼Î±Ï„Î±", f"{N2} / {min_classes2}")
        except Exception:
            st.caption("Î”ÎµÎ½ Î®Ï„Î±Î½ Î´Ï…Î½Î±Ï„Î® Î· Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î³Î¹Î± Ï€ÏÎ¿ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·.")

run_16 = st.button("ğŸ§ª Î‘ÎÎ‘Î›Î¥Î¤Î™ÎšÎ‘ Î’Î—ÎœÎ‘Î¤Î‘", type="secondary", use_container_width=True)

if run_16:
    if missing:
        st.error("Î”ÎµÎ½ ÎµÎ¯Î½Î±Î¹ Î´Ï…Î½Î±Ï„Î® Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·: Î»ÎµÎ¯Ï€Î¿Ï…Î½ modules.")
    elif up_16 is None:
        st.warning("Î ÏÏÏ„Î± Î±Î½Î­Î²Î±ÏƒÎµ Î­Î½Î± Excel.")
    else:
        try:
            input_path = ROOT / _timestamped("INPUT_STEP1", ".xlsx")
            with open(input_path, "wb") as f:
                f.write(up_16.getbuffer())

            m = _load_module("export_step1_6_per_scenario", ROOT / "export_step1_6_per_scenario.py")
            out_path = ROOT / out_name_16

            with st.spinner("Î¤ÏÎ­Ï‡Î¿Ï…Î½ Ï„Î± Î’Î®Î¼Î±Ï„Î± 1â†’6..."):
                m.build_step1_6_per_scenario(str(input_path), str(out_path), pick_step4=pick_step4)

            st.success("âœ… ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ Î· Ï€Î±ÏÎ±Î³Ï‰Î³Î® ÏƒÎµÎ½Î±ÏÎ¯Ï‰Î½ (1â†’6).")
            st.download_button(
                "â¬‡ï¸ ÎšÎ±Ï„Î­Î²Î±ÏƒÎµ Excel (1â†’6)",
                data=_read_file_bytes(out_path),
                file_name=out_path.name,
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )
        except Exception as e:
            st.exception(e)

st.caption("Wrapper Î¼ÏŒÎ½Î¿ â€” Ï„Î± modules Ï†Î¿ÏÏ„ÏÎ½Î¿Î½Ï„Î±Î¹ ÏŒÏ€Ï‰Ï‚ ÎµÎ¯Î½Î±Î¹, Ï‡Ï‰ÏÎ¯Ï‚ ÎºÎ±Î¼Î¯Î± Î±Î»Î»Î±Î³Î® ÏƒÏ„Î· Î»Î¿Î³Î¹ÎºÎ®.")